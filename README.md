# 📂 PatchCore Colab 산출물 파일 설명 (최종)

## 1. `wrn50_l3.onnx` → **특징 추출기**

* **무엇?**
  WideResNet-50-2 백본을 ONNX로 내보낸 파일.
  이미지를 넣으면 **layer3 특징맵**을 출력합니다 (출력: `[1,1024,14,14]`).

* **원래 백본 구조**

  ```
  conv1 → layer1 → layer2 → layer3 → layer4 → GAP → 분류 결과
  ```

* **Layer별 특징 차이**

  * **Layer1, Layer2**: 저수준(low-level) 특징
    → 에지(edge), 질감(texture), 색상 대비
    → 너무 원시적이라 결함 탐지에 적합하지 않음
  * **Layer4**: 고수준(high-level) 특징
    → “개, 고양이, 자동차” 같은 클래스 구분에 특화
    → 너무 추상적이라 미세 결함(스크래치, 기포)을 놓칠 수 있음
  * **Layer3**: 중간 수준(middle-level) 특징
    → 국소적 모양(스크래치, 구멍) + 추상적 맥락(물체의 일관성)
    → 결함 탐지에 가장 적합 (표현력 + 해상도 14×14)

* **왜 필요?**
  PyTorch를 쓸 수 없는 .NET 환경에서 ONNX Runtime을 통해
  PatchCore가 anomaly score 계산에 필요한 **layer3 임베딩**을 얻습니다.

* **비유**: 원재료(이미지)를 “밀가루 반죽(특징맵)”으로 바꿔주는 믹서기.

---

## 2. `gallery_f32.bin` → **정상 도감(Embeddings)**

* **무엇?**
  학습 데이터에서 추출한 정상 샘플들의 **feature 메모리**.
  float32 배열로 `(N×1024)` 크기의 row-major 구조이며 각 행은 **L2 정규화**되어 있음.

* **왜 필요?**
  새 이미지가 들어오면, 이 갤러리와 **코사인 거리(1 − dot)**를 비교하여
  정상/비정상 여부를 판정합니다.

* **개념 확장**

  * **임베딩(Embedding)**: 이미지를 **숫자 벡터**로 바꾼 것
    (예: 고양이 → `[0.12, -0.33, ..., 0.48]`)
    → 마치 사람을 “이름, 키, 나이” 특징만 뽑아 요약하는 것
  * **임베딩들의 모음**: 여러 이미지에서 뽑아낸 벡터들을 모아둔 행렬 `[N, D]`
    → 반 학생 30명의 키/몸무게/나이를 표로 만든 것
  * **갤러리(Gallery)**: 정상 데이터만 모아둔 임베딩 집합 (정상 도감)
    → 새 샘플이 정상인지 판단하려면 이 도감과 얼마나 닮았는지 비교
  * **최근접 거리(코사인)**: 새 샘플이 갤러리 중 어느 것과 가장 가까운지
    → 전학생이 반 친구 중 누구랑 제일 닮았는지 찾는 것
  * **L2 정규화**: 모든 벡터 길이를 1로 맞춤 → 방향만 비교
    → 키(크기)는 무시하고 “얼굴 생김새 방향”만 비교하는 것

---

## 3. `threshold.json` → **컷오프(합격선)**

* **무엇?**
  학습 데이터(Good set)의 분포에서 산출된 anomaly score 임계값.

  ```json
  { "value": 0.0509, "metric": "cosine" }
  ```

* **왜 필요?**
  추론 시

  * `score > threshold` → **NotGood**
  * `score ≤ threshold` → **Good**

* **운영 팁**

  * 현장 초기: threshold.json 값을 기본 컷으로 사용
  * 이후 운영 중: **사용자 UI에서 상수 컷 조정 가능**하게 두는 게 좋음
    (예: `2.0` 입력 → score < 2.0이면 NG로 강제 판정)

* **비유**: 시험 합격선 같은 **커트라인**.

---

## 4. `meta.json` → **전처리·후처리 레시피**

* **무엇?**
  모델 실행/전처리에 필요한 환경 메타데이터.
  예시:

  ```json
  {
    "input_size": 224,
    "mean": [0.485, 0.456, 0.406],
    "std": [0.229, 0.224, 0.225],
    "grid": [14,14],
    "metric": "cosine",
    "backbone": "wrn50_l3"
  }
  ```

* **왜 필요?**
  C#과 Colab에서 **동일한 전처리·후처리 규칙**을 맞추기 위해.

  * `input_size`: crop 크기 (224×224)
  * `mean/std`: 정규화 값 (픽셀 → 텐서 변환)
  * `grid`: `[14,14]`, patch별 distance를 heatmap으로 복원할 때 필요
  * `metric`: `"cosine"`, 거리 계산 방식 통일
  * `backbone`: `"wrn50_l3"`, 어떤 네트워크인지 기록용

* **비유**: 요리 레시피의 “재료 손질법”.

---

# ✅ 정리

* **C# 필수**

  * `wrn50_l3.onnx` (특징 추출기)
  * `gallery_f32.bin` (정상 도감)
  * `threshold.json` (합격선)
  * `meta.json` (레시피)

* **Python/백업 전용**

  * `patchcore_params.pkl` (PyTorch 파라미터)
  * `nnscorer_search_index.faiss` (Python용 검색 인덱스)

즉, **C# 추론·오버레이 구현에 필요한 건 딱 4개**입니다.
