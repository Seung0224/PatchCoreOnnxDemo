{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1TPbKPpm9cNxSYE33YozMuhR5QXvfL1dS","timestamp":1759148297289}],"gpuType":"T4","authorship_tag":"ABX9TyNei/8oNMxoWGqJ9kO5SrgU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bN4xEYyvRpBy","executionInfo":{"status":"ok","timestamp":1759146952480,"user_tz":-540,"elapsed":25,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"4043cce3-1a72-41e2-eccb-6e028af61905"},"outputs":[{"output_type":"stream","name":"stdout","text":["DATA_NAME = bottle\n","DRIVE_ARCHIVE_NAME = mytec.tar\n","RESULT_ROOT = /content/result\n","DATE = 20250929\n","WORK_DIR = /content/work\n","MODELS_DIR = /content/work/models\n","DATA_DIR = /content/datasets/mvtec\n","RESULT_DIR = /content/result/20250929\n","MAKE_META_JSON = 1\n"]}],"source":["# ===[ 셀 0: 환경 변수 ]========================================================\n","import os, datetime, pathlib, json\n","\n","# -----[ 사용자가 바꿀 수 있는 부분 ]-----\n","# 학습할 MVTec 클래스 이름 (예: bottle, cable, capsule, hazelnut 등)\n","os.environ[\"DATA_NAME\"] = \"bottle\"\n","\n","# 내 구글드라이브에 있는 데이터 아카이브 기본 이름\n","# ※ 기본값: \"mytec.tar\" (혹시 'mvtec.tar' 또는 'mvtec*.tar*' 만 있을 수도 있어요. 아래 셀에서 자동 폴백합니다)\n","os.environ[\"DRIVE_ARCHIVE_NAME\"] = \"mytec.tar\"\n","\n","# 모든 결과를 모을 루트 폴더\n","os.environ[\"RESULT_ROOT\"] = \"/content/result\"\n","\n","# -----[ 유도/고정 값들 (보통 수정 불필요) ]-----\n","DATE = datetime.datetime.now().strftime(\"%Y%m%d\")\n","os.environ[\"DATE\"] = DATE\n","\n","WORK_DIR = \"/content/work\"                             # 내부 작업 디렉토리\n","MODELS_DIR = f\"{WORK_DIR}/models\"                      # patchcore 모델 저장 루트\n","DATA_DIR   = \"/content/datasets/mvtec\"                 # 데이터셋 풀린 위치\n","RESULT_DIR = f\"{os.environ['RESULT_ROOT']}/{DATE}\"     # 최종 산출물 모이는 곳\n","\n","os.environ[\"WORK_DIR\"]   = WORK_DIR\n","os.environ[\"MODELS_DIR\"] = MODELS_DIR\n","os.environ[\"DATA_DIR\"]   = DATA_DIR\n","os.environ[\"RESULT_DIR\"] = RESULT_DIR\n","\n","# 옵션: C#용 추가 산출물(간단 메타 json) 만들지 여부(0/1)\n","os.environ[\"MAKE_META_JSON\"] = \"1\"\n","\n","# 보기 좋게 출력\n","for k in [\"DATA_NAME\",\"DRIVE_ARCHIVE_NAME\",\"RESULT_ROOT\",\"DATE\",\"WORK_DIR\",\"MODELS_DIR\",\"DATA_DIR\",\"RESULT_DIR\",\"MAKE_META_JSON\"]:\n","    print(f\"{k} = {os.environ[k]}\")\n"]},{"cell_type":"code","source":["%%bash\n","set -euo pipefail\n","\n","nvidia-smi || echo \"⚠️ GPU가 안 보입니다. (CPU로도 동작은 하지만 느릴 수 있어요)\"\n","python - <<'PY'\n","import torch\n","print(\"PyTorch CUDA available:\", torch.cuda.is_available())\n","PY\n","\n","# 리포 클론 & 설치\n","cd /content\n","git clone -q https://github.com/amazon-science/patchcore-inspection.git || true\n","cd /content/patchcore-inspection\n","\n","pip install -q -r requirements.txt\n","pip install -q -e .\n","\n","# FAISS: GPU 우선, 실패 시 CPU\n","pip install -q faiss-gpu || pip install -q faiss-cpu\n","\n","# 설치 확인\n","python - << 'PY'\n","import importlib, sys\n","for m in [\"patchcore\", \"faiss\"]:\n","    try:\n","        importlib.import_module(m)\n","        print(f\"[OK] import {m}\")\n","    except Exception as e:\n","        print(f\"[ERR] import {m}:\", e, file=sys.stderr)\n","PY\n","\n","# PYTHONPATH 설정\n","echo \"export PYTHONPATH=/content/patchcore-inspection/src\" >> /root/.bashrc\n","export PYTHONPATH=/content/patchcore-inspection/src\n","echo \"[INFO] PYTHONPATH=$PYTHONPATH\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W8Nha5YsTLk-","executionInfo":{"status":"ok","timestamp":1759147013994,"user_tz":-540,"elapsed":59943,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"80cc9bc9-65c6-437f-a6b0-7dd7b994099b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 29 11:55:54 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   63C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","PyTorch CUDA available: True\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 3.3 MB/s eta 0:00:00\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.4/31.4 MB 75.7 MB/s eta 0:00:00\n","[OK] import patchcore\n","[OK] import faiss\n","[INFO] PYTHONPATH=/content/patchcore-inspection/src\n"]},{"output_type":"stream","name":"stderr","text":["ERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\n","ERROR: No matching distribution found for faiss-gpu\n"]}]},{"cell_type":"code","source":["# ===[ 셀 2: Drive 마운트 & 데이터 추출 ]=====================================\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","print(\"[OK] Drive mounted\")\n","\n","import os, subprocess, glob, shutil, pathlib, sys\n","\n","DATA_NAME  = os.environ[\"DATA_NAME\"]\n","DATA_DIR   = os.environ[\"DATA_DIR\"]\n","ARCH_NAME  = os.environ[\"DRIVE_ARCHIVE_NAME\"]  # 기본 \"mytec.tar\"\n","result     = None\n","\n","# 1) 우선 정확히 'ARCH_NAME'으로 찾기\n","cands = !find /content/drive -maxdepth 5 -type f -iname \"{ARCH_NAME}\"\n","if not cands:\n","    # 2) 흔한 오탈자/변형: mvtec*.tar*\n","    cands = !find /content/drive -maxdepth 5 -type f \\( -iname \"mvtec*.tar\" -o -iname \"mvtec*.tar.gz\" -o -iname \"mvtec*.tgz\" -o -iname \"mvtec*.tar.xz\" -o -iname \"mvtec*.zip\" \\)\n","\n","if cands:\n","    archive = cands[0]\n","    print(\"[INFO] Found archive:\", archive)\n","else:\n","    archive = \"\"\n","    print(\"[WARN] 아카이브 파일을 찾지 못했습니다. 대신 드라이브 안의 'mvtec' 폴더를 찾습니다.\")\n","\n","# 3) DATA_DIR 준비\n","os.makedirs(DATA_DIR, exist_ok=True)\n","\n","def flatten_if_needed(out_root):\n","    # mvtec / mvtec_ad / mvtec_anomaly_detection 중첩 제거\n","    for name in (\"mvtec\",\"mvtec_ad\",\"mvtec_anomaly_detection\"):\n","        p = os.path.join(out_root, name)\n","        if os.path.isdir(p) and os.path.isdir(os.path.join(p, DATA_NAME)):\n","            # 안으로 들어가서 평탄화\n","            for item in os.listdir(p):\n","                src = os.path.join(p, item)\n","                dst = os.path.join(out_root, item)\n","                if not os.path.exists(dst):\n","                    shutil.move(src, dst)\n","            shutil.rmtree(p, ignore_errors=True)\n","            print(f\"[INFO] Flattened one level: {name}\")\n","\n","# 4) 폴더 링크 or 아카이브 추출\n","if archive:\n","    # archive를 DATA_DIR에 직접 풀기\n","    # 먼저 비어있으면 그대로, 뭔가 있으면 일단 유지(덮어쓰지 않음)\n","    # (중복풀이는 느려지므로, 보통 한번만 풀고 재사용)\n","    need_extract = not os.path.isdir(os.path.join(DATA_DIR, DATA_NAME))\n","    print(\"[INFO] Need extract?:\", need_extract)\n","    if need_extract:\n","        # 확장자별로 풀기\n","        if archive.lower().endswith((\".tar\",\".tar.gz\",\".tgz\",\".tar.xz\")):\n","            !tar -xf \"{archive}\" -C \"{DATA_DIR}\"\n","        elif archive.lower().endswith(\".zip\"):\n","            !unzip -q \"{archive}\" -d \"{DATA_DIR}\"\n","        else:\n","            raise RuntimeError(f\"Unsupported archive type: {archive}\")\n","\n","        flatten_if_needed(DATA_DIR)\n","else:\n","    # archive가 없을 때: Drive 안에 기존 mvtec 디렉토리가 있으면 심볼릭 링크\n","    cands_dir = !find /content/drive -maxdepth 5 -type d \\( -name \"mvtec\" -o -name \"mvtec_ad\" -o -name \"mvtec_anomaly_detection\" \\)\n","    if cands_dir:\n","        src_dir = cands_dir[0]\n","        print(\"[INFO] Linking dataset dir:\", src_dir, \"->\", DATA_DIR)\n","        if os.path.islink(DATA_DIR) or os.path.exists(DATA_DIR):\n","            # 이미 있으면 유지\n","            pass\n","        else:\n","            os.symlink(src_dir, DATA_DIR, target_is_directory=True)\n","        flatten_if_needed(DATA_DIR)\n","    else:\n","        raise RuntimeError(\"Drive에서 아카이브/디렉토리를 찾지 못했습니다. mytec.tar(또는 mvtec*.tar*)를 Drive에 두세요.\")\n","\n","# 5) 최종 검증\n","ok_path = os.path.join(DATA_DIR, DATA_NAME, \"train\", \"good\")\n","assert os.path.isdir(ok_path), f\"[ERROR] {ok_path} 가 존재하지 않습니다.\"\n","print(\"[READY]\", ok_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EgcmXh_GTOyg","executionInfo":{"status":"ok","timestamp":1759147147188,"user_tz":-540,"elapsed":121755,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"cd9af674-9bb5-4a7b-f8ba-eb417c6588e0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[OK] Drive mounted\n","[INFO] Found archive: /content/drive/MyDrive/mvtec.tar\n","[INFO] Need extract?: True\n","[READY] /content/datasets/mvtec/bottle/train/good\n"]}]},{"cell_type":"code","source":["%%bash\n","set -euo pipefail\n","\n","export PYTHONPATH=/content/patchcore-inspection/src\n","\n","DATA_NAME=\"${DATA_NAME:-bottle}\"\n","DATA_DIR=\"${DATA_DIR:-/content/datasets/mvtec}\"\n","MODELS_DIR=\"${MODELS_DIR:-/content/work/models}\"\n","DATE=\"${DATE:-$(date +%Y%m%d)}\"\n","\n","# FAISS GPU 감지\n","if python - <<'PY'\n","import sys\n","try:\n","    import faiss\n","    ok = hasattr(faiss, \"StandardGpuResources\") and hasattr(faiss, \"GpuIndexFlatL2\")\n","except Exception:\n","    ok = False\n","sys.exit(0 if ok else 1)\n","PY\n","then\n","  FAISS_FLAG=\"--faiss_on_gpu\"\n","  echo \"[INFO] faiss-gpu detected → using GPU index\"\n","else\n","  FAISS_FLAG=\"\"\n","  echo \"[WARN] faiss-gpu NOT detected → using CPU index (IndexFlatL2)\"\n","fi\n","\n","LOG_GROUP=\"IM224_WR50_L3_ONLY_P01_D1024_PS-3_AN-1_${DATE}\"\n","mkdir -p \"$MODELS_DIR\"\n","\n","python /content/patchcore-inspection/bin/run_patchcore.py \\\n","  --gpu 0 --seed 0 --save_patchcore_model \\\n","  --log_group \"$LOG_GROUP\" \\\n","  --log_project MVTecAD_Results \\\n","  \"$MODELS_DIR\" \\\n","  patch_core -b wideresnet50 -le layer3 --pretrain_embed_dimension 1024 --target_embed_dimension 1024 \\\n","  --anomaly_scorer_num_nn 1 --patchsize 3 ${FAISS_FLAG} \\\n","  sampler -p 0.1 approx_greedy_coreset \\\n","  dataset --resize 256 --imagesize 224 -d \"$DATA_NAME\" mvtec \"$DATA_DIR\"\n","\n","echo \"[OK] Training done.\"\n","echo \"[INFO] Models under: $MODELS_DIR/$LOG_GROUP/$DATA_NAME\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_4BtfaITQoY","executionInfo":{"status":"ok","timestamp":1759147200845,"user_tz":-540,"elapsed":45883,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"6c902683-49ba-41ac-d4aa-3ebac227e5a0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[WARN] faiss-gpu NOT detected → using CPU index (IndexFlatL2)\n","Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n","[OK] Training done.\n","[INFO] Models under: /content/work/models/IM224_WR50_L3_ONLY_P01_D1024_PS-3_AN-1_20250929/bottle\n"]},{"output_type":"stream","name":"stderr","text":["INFO:__main__:Command line arguments: /content/patchcore-inspection/bin/run_patchcore.py --gpu 0 --seed 0 --save_patchcore_model --log_group IM224_WR50_L3_ONLY_P01_D1024_PS-3_AN-1_20250929 --log_project MVTecAD_Results /content/work/models patch_core -b wideresnet50 -le layer3 --pretrain_embed_dimension 1024 --target_embed_dimension 1024 --anomaly_scorer_num_nn 1 --patchsize 3 sampler -p 0.1 approx_greedy_coreset dataset --resize 256 --imagesize 224 -d bottle mvtec /content/datasets/mvtec\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","INFO:__main__:Evaluating dataset [mvtec_bottle] (1/1)...\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Wide_ResNet50_2_Weights.IMAGENET1K_V1`. You can also use `weights=Wide_ResNet50_2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","\r  0%|          | 0.00/132M [00:00<?, ?B/s]\r  4%|▍         | 5.75M/132M [00:00<00:02, 60.0MB/s]\r  9%|▉         | 11.6M/132M [00:00<00:02, 60.9MB/s]\r 23%|██▎       | 30.9M/132M [00:00<00:00, 125MB/s] \r 35%|███▍      | 45.6M/132M [00:00<00:00, 137MB/s]\r 45%|████▍     | 58.8M/132M [00:00<00:00, 137MB/s]\r 55%|█████▍    | 71.9M/132M [00:00<00:00, 129MB/s]\r 64%|██████▍   | 84.4M/132M [00:00<00:00, 128MB/s]\r 73%|███████▎  | 96.6M/132M [00:00<00:00, 126MB/s]\r 83%|████████▎ | 109M/132M [00:00<00:00, 127MB/s] \r 92%|█████████▏| 121M/132M [00:01<00:00, 122MB/s]\r100%|██████████| 132M/132M [00:01<00:00, 123MB/s]\n","INFO:__main__:Training models (1/1)\n","\n","\rComputing support features...:   0%|          | 0/105 [00:00<?, ?it/s]\u001b[A\n","\rComputing support features...:   1%|          | 1/105 [00:01<02:35,  1.49s/it]\u001b[A\n","\rComputing support features...:   3%|▎         | 3/105 [00:01<00:43,  2.33it/s]\u001b[A\n","\rComputing support features...:   5%|▍         | 5/105 [00:01<00:23,  4.23it/s]\u001b[A\n","\rComputing support features...:   7%|▋         | 7/105 [00:01<00:16,  5.77it/s]\u001b[A\n","\rComputing support features...:   9%|▊         | 9/105 [00:02<00:12,  7.66it/s]\u001b[A\n","\rComputing support features...:  10%|█         | 11/105 [00:02<00:14,  6.31it/s]\u001b[A\n","\rComputing support features...:  12%|█▏        | 13/105 [00:02<00:11,  8.16it/s]\u001b[A\n","\rComputing support features...:  15%|█▌        | 16/105 [00:02<00:08, 10.94it/s]\u001b[A\n","\rComputing support features...:  17%|█▋        | 18/105 [00:02<00:07, 11.49it/s]\u001b[A\n","\rComputing support features...:  19%|█▉        | 20/105 [00:02<00:06, 12.87it/s]\u001b[A\n","\rComputing support features...:  21%|██        | 22/105 [00:03<00:06, 13.19it/s]\u001b[A\n","\rComputing support features...:  23%|██▎       | 24/105 [00:03<00:05, 13.96it/s]\u001b[A\n","\rComputing support features...:  25%|██▍       | 26/105 [00:03<00:05, 15.30it/s]\u001b[A\n","\rComputing support features...:  27%|██▋       | 28/105 [00:03<00:04, 16.03it/s]\u001b[A\n","\rComputing support features...:  29%|██▊       | 30/105 [00:03<00:04, 16.76it/s]\u001b[A\n","\rComputing support features...:  30%|███       | 32/105 [00:03<00:04, 16.87it/s]\u001b[A\n","\rComputing support features...:  32%|███▏      | 34/105 [00:03<00:04, 17.69it/s]\u001b[A\n","\rComputing support features...:  35%|███▌      | 37/105 [00:03<00:03, 19.34it/s]\u001b[A\n","\rComputing support features...:  37%|███▋      | 39/105 [00:04<00:04, 15.49it/s]\u001b[A\n","\rComputing support features...:  39%|███▉      | 41/105 [00:04<00:04, 15.78it/s]\u001b[A\n","\rComputing support features...:  42%|████▏     | 44/105 [00:04<00:03, 16.88it/s]\u001b[A\n","\rComputing support features...:  44%|████▍     | 46/105 [00:04<00:03, 16.61it/s]\u001b[A\n","\rComputing support features...:  46%|████▌     | 48/105 [00:04<00:03, 17.19it/s]\u001b[A\n","\rComputing support features...:  49%|████▊     | 51/105 [00:04<00:02, 18.13it/s]\u001b[A\n","\rComputing support features...:  51%|█████▏    | 54/105 [00:04<00:02, 18.49it/s]\u001b[A\n","\rComputing support features...:  53%|█████▎    | 56/105 [00:05<00:03, 15.81it/s]\u001b[A\n","\rComputing support features...:  55%|█████▌    | 58/105 [00:05<00:03, 15.38it/s]\u001b[A\n","\rComputing support features...:  57%|█████▋    | 60/105 [00:05<00:02, 16.35it/s]\u001b[A\n","\rComputing support features...:  60%|██████    | 63/105 [00:05<00:02, 17.59it/s]\u001b[A\n","\rComputing support features...:  62%|██████▏   | 65/105 [00:05<00:02, 17.01it/s]\u001b[A\n","\rComputing support features...:  64%|██████▍   | 67/105 [00:05<00:02, 17.49it/s]\u001b[A\n","\rComputing support features...:  66%|██████▌   | 69/105 [00:05<00:02, 16.33it/s]\u001b[A\n","\rComputing support features...:  68%|██████▊   | 71/105 [00:05<00:02, 16.86it/s]\u001b[A\n","\rComputing support features...:  70%|██████▉   | 73/105 [00:06<00:02, 15.87it/s]\u001b[A\n","\rComputing support features...:  72%|███████▏  | 76/105 [00:06<00:01, 17.24it/s]\u001b[A\n","\rComputing support features...:  74%|███████▍  | 78/105 [00:06<00:01, 17.13it/s]\u001b[A\n","\rComputing support features...:  76%|███████▌  | 80/105 [00:06<00:01, 17.74it/s]\u001b[A\n","\rComputing support features...:  78%|███████▊  | 82/105 [00:06<00:01, 17.40it/s]\u001b[A\n","\rComputing support features...:  80%|████████  | 84/105 [00:06<00:01, 16.83it/s]\u001b[A\n","\rComputing support features...:  82%|████████▏ | 86/105 [00:06<00:01, 16.59it/s]\u001b[A\n","\rComputing support features...:  84%|████████▍ | 88/105 [00:06<00:00, 17.28it/s]\u001b[A\n","\rComputing support features...:  86%|████████▌ | 90/105 [00:07<00:00, 17.49it/s]\u001b[A\n","\rComputing support features...:  89%|████████▊ | 93/105 [00:07<00:00, 20.65it/s]\u001b[A\n","\rComputing support features...:  92%|█████████▏| 97/105 [00:07<00:00, 25.28it/s]\u001b[A\n","\rComputing support features...:  97%|█████████▋| 102/105 [00:07<00:00, 30.58it/s]\u001b[A\n","\r                                                                                \u001b[A\rSubsampling...:   0%|          | 0/4096 [00:00<?, ?it/s]\rSubsampling...:   2%|▏         | 98/4096 [00:00<00:04, 977.43it/s]\rSubsampling...:   9%|▉         | 384/4096 [00:00<00:01, 2081.90it/s]\rSubsampling...:  16%|█▋        | 669/4096 [00:00<00:01, 2430.15it/s]\rSubsampling...:  23%|██▎       | 954/4096 [00:00<00:01, 2593.48it/s]\rSubsampling...:  30%|███       | 1239/4096 [00:00<00:01, 2685.65it/s]\rSubsampling...:  37%|███▋      | 1523/4096 [00:00<00:00, 2737.24it/s]\rSubsampling...:  44%|████▍     | 1809/4096 [00:00<00:00, 2774.27it/s]\rSubsampling...:  51%|█████     | 2094/4096 [00:00<00:00, 2795.43it/s]\rSubsampling...:  58%|█████▊    | 2380/4096 [00:00<00:00, 2814.08it/s]\rSubsampling...:  65%|██████▍   | 2662/4096 [00:01<00:00, 2766.78it/s]\rSubsampling...:  72%|███████▏  | 2939/4096 [00:01<00:00, 2744.81it/s]\rSubsampling...:  79%|███████▊  | 3223/4096 [00:01<00:00, 2771.15it/s]\rSubsampling...:  86%|████████▌ | 3505/4096 [00:01<00:00, 2785.43it/s]\rSubsampling...:  93%|█████████▎| 3789/4096 [00:01<00:00, 2801.27it/s]\rSubsampling...:  99%|█████████▉| 4075/4096 [00:01<00:00, 2815.59it/s]\rSubsampling...: 100%|██████████| 4096/4096 [00:01<00:00, 2697.15it/s]\n","INFO:__main__:Embedding test data with models (1/1)\n","\rInferring...:   0%|          | 0/42 [00:00<?, ?it/s]\rInferring...:   2%|▏         | 1/42 [00:01<00:51,  1.26s/it]\rInferring...:   5%|▍         | 2/42 [00:01<00:27,  1.44it/s]\rInferring...:   7%|▋         | 3/42 [00:01<00:19,  2.04it/s]\rInferring...:  10%|▉         | 4/42 [00:01<00:14,  2.71it/s]\rInferring...:  12%|█▏        | 5/42 [00:02<00:11,  3.08it/s]\rInferring...:  14%|█▍        | 6/42 [00:02<00:10,  3.55it/s]\rInferring...:  17%|█▋        | 7/42 [00:02<00:09,  3.89it/s]\rInferring...:  19%|█▉        | 8/42 [00:02<00:08,  4.24it/s]\rInferring...:  21%|██▏       | 9/42 [00:03<00:07,  4.60it/s]\rInferring...:  24%|██▍       | 10/42 [00:03<00:06,  4.69it/s]\rInferring...:  26%|██▌       | 11/42 [00:03<00:06,  4.88it/s]\rInferring...:  29%|██▊       | 12/42 [00:03<00:05,  5.20it/s]\rInferring...:  31%|███       | 13/42 [00:03<00:05,  5.29it/s]\rInferring...:  33%|███▎      | 14/42 [00:03<00:05,  4.99it/s]\rInferring...:  36%|███▌      | 15/42 [00:04<00:05,  5.02it/s]\rInferring...:  38%|███▊      | 16/42 [00:04<00:04,  5.28it/s]\rInferring...:  40%|████      | 17/42 [00:04<00:04,  5.60it/s]\rInferring...:  43%|████▎     | 18/42 [00:04<00:04,  5.63it/s]\rInferring...:  45%|████▌     | 19/42 [00:04<00:03,  6.11it/s]\rInferring...:  48%|████▊     | 20/42 [00:04<00:03,  6.01it/s]\rInferring...:  50%|█████     | 21/42 [00:05<00:03,  6.19it/s]\rInferring...:  52%|█████▏    | 22/42 [00:05<00:03,  6.18it/s]\rInferring...:  55%|█████▍    | 23/42 [00:05<00:03,  6.26it/s]\rInferring...:  57%|█████▋    | 24/42 [00:05<00:02,  6.27it/s]\rInferring...:  60%|█████▉    | 25/42 [00:05<00:02,  6.28it/s]\rInferring...:  64%|██████▍   | 27/42 [00:05<00:01,  8.21it/s]\rInferring...:  69%|██████▉   | 29/42 [00:06<00:01,  9.68it/s]\rInferring...:  74%|███████▍  | 31/42 [00:06<00:01, 10.92it/s]\rInferring...:  79%|███████▊  | 33/42 [00:06<00:00, 11.89it/s]\rInferring...:  83%|████████▎ | 35/42 [00:06<00:00, 12.48it/s]\rInferring...:  88%|████████▊ | 37/42 [00:06<00:00, 13.05it/s]\rInferring...:  93%|█████████▎| 39/42 [00:06<00:00, 13.43it/s]\rInferring...:  98%|█████████▊| 41/42 [00:06<00:00, 13.70it/s]\r                                                             \rINFO:__main__:Computing evaluation metrics.\n","INFO:__main__:instance_auroc: 1.000\n","INFO:__main__:full_pixel_auroc: 0.973\n","INFO:__main__:anomaly_pixel_auroc: 0.964\n","INFO:patchcore.patchcore:Saving PatchCore data.\n","INFO:__main__:\n","\n","-----\n","\n","INFO:patchcore.utils:instance_auroc: 1.000\n","INFO:patchcore.utils:full_pixel_auroc: 0.973\n","INFO:patchcore.utils:anomaly_pixel_auroc: 0.964\n"]}]},{"cell_type":"code","source":["# ===[ 셀 4: 결과 모으기 + wrn50_l3.onnx Export (경로 고정형 + 폴백) ]===\n","! pip install onnx\n","import os, glob, shutil, json\n","from pathlib import Path\n","\n","DATA_NAME  = os.environ[\"DATA_NAME\"]          # e.g. \"bottle\"\n","DATE       = os.environ[\"DATE\"]               # e.g. \"20250929\"\n","MODELS_DIR = os.environ[\"MODELS_DIR\"]         # \"/content/work/models\"\n","RESULT_DIR = os.environ[\"RESULT_DIR\"]         # \"/content/result/<DATE>\"\n","Path(RESULT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","# 1) 너가 알려준 “정확한” 경로 우선 시도\n","preferred = Path(MODELS_DIR) / \"MVTecAD_Results\" / f\"IM224_WR50_L3_ONLY_P01_D1024_PS-3_AN-1_{DATE}\" / \"models\" / f\"mvtec_{DATA_NAME}\"\n","MODEL_DIR = None\n","if preferred.is_dir():\n","    MODEL_DIR = preferred\n","else:\n","    # 2) 날짜가 다르거나 이름이 조금 다른 경우를 대비한 폴백 탐색\n","    cands = sorted(\n","        Path(MODELS_DIR).glob(f\"MVTecAD_Results/**/models/mvtec_{DATA_NAME}\"),\n","        key=lambda p: p.stat().st_mtime if p.exists() else 0,\n","        reverse=True,\n","    )\n","    if cands:\n","        MODEL_DIR = cands[0]\n","\n","if MODEL_DIR is None or not MODEL_DIR.exists():\n","    raise AssertionError(f\"[ERROR] 모델 폴더를 찾지 못했습니다.\\n  tried: {preferred}\\n  searched: {MODELS_DIR}/MVTecAD_Results/**/models/mvtec_{DATA_NAME}\")\n","\n","print(\"[INFO] Selected MODEL_DIR:\", MODEL_DIR)\n","\n","# 3) 핵심 파일만 결과 폴더로 복사\n","for name in [\"patchcore_params.pkl\", \"nnscorer_search_index.faiss\"]:\n","    src = MODEL_DIR / name\n","    if src.exists():\n","        dst = Path(RESULT_DIR) / name\n","        shutil.copy2(src, dst)\n","        print(\"[COPY]\", src.name, \"->\", dst)\n","    else:\n","        print(\"[WARN] missing:\", src)\n","\n","# 4) wrn50_l3.onnx 내보내기 (layer3만)\n","onnx_path = Path(RESULT_DIR) / \"wrn50_l3.onnx\"\n","print(\"[EXPORT] ONNX ->\", onnx_path)\n","\n","try:\n","    import torch, torch.nn as nn\n","    import torchvision.models as tvm\n","except Exception:\n","    import sys, subprocess\n","    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"], check=True)\n","    import torch, torch.nn as nn\n","    import torchvision.models as tvm\n","\n","class WRN50_L3(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        try:\n","            W = tvm.Wide_ResNet50_2_Weights.IMAGENET1K_V1\n","            m = tvm.wide_resnet50_2(weights=W)\n","        except Exception:\n","            m = tvm.wide_resnet50_2(pretrained=True)\n","        self.conv1, self.bn1, self.relu, self.maxpool = m.conv1, m.bn1, m.relu, m.maxpool\n","        self.layer1, self.layer2, self.layer3 = m.layer1, m.layer2, m.layer3\n","    def forward(self, x):\n","        x = self.conv1(x); x = self.bn1(x); x = self.relu(x); x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)          # [B,512,28,28]\n","        l3 = self.layer3(x)         # [B,1024,14,14]\n","        return l3\n","\n","model = WRN50_L3().eval()\n","dummy = torch.randn(1,3,224,224)\n","torch.onnx.export(\n","    model, dummy, str(onnx_path),\n","    input_names=[\"input\"], output_names=[\"layer3\"],\n","    opset_version=12,\n","    dynamic_axes={\"input\":{0:\"batch\"}, \"layer3\":{0:\"batch\"}},\n",")\n","print(\"[OK] Exported ONNX:\", onnx_path)\n","\n","# 5) (옵션) 메타\n","if os.environ.get(\"MAKE_META_JSON\",\"1\") == \"1\":\n","    meta = {\n","        \"backbone\": \"wide_resnet50_2\",\n","        \"layers\": [\"layer3\"],\n","        \"input_size\": 224,\n","        \"mean\": [0.485, 0.456, 0.406],\n","        \"std\":  [0.229, 0.224, 0.225],\n","        \"patchsize\": 3,\n","        \"grid\": [14,14],\n","        \"metric\": \"cosine\",\n","        \"data_name\": DATA_NAME,\n","        \"model_dir\": str(MODEL_DIR),\n","    }\n","    with open(Path(RESULT_DIR)/\"meta.json\",\"w\") as f:\n","        json.dump(meta, f, indent=2)\n","    print(\"[WRITE] meta.json\")\n","\n","print(\"\\n[LIST] Result dir:\")\n","for p in sorted(Path(RESULT_DIR).glob(\"*\")):\n","    print(\" -\", p.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Px2XamuTUlQ","executionInfo":{"status":"ok","timestamp":1759147589230,"user_tz":-540,"elapsed":11683,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"2ea2506c-0a10-4a76-d4a5-a7a63674fe6e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n","Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","Successfully installed onnx-1.19.0\n","[INFO] Selected MODEL_DIR: /content/work/models/MVTecAD_Results/IM224_WR50_L3_ONLY_P01_D1024_PS-3_AN-1_20250929/models/mvtec_bottle\n","[COPY] patchcore_params.pkl -> /content/result/20250929/patchcore_params.pkl\n","[COPY] nnscorer_search_index.faiss -> /content/result/20250929/nnscorer_search_index.faiss\n","[EXPORT] ONNX -> /content/result/20250929/wrn50_l3.onnx\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3394399800.py:74: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n","  torch.onnx.export(\n"]},{"output_type":"stream","name":"stdout","text":["[OK] Exported ONNX: /content/result/20250929/wrn50_l3.onnx\n","[WRITE] meta.json\n","\n","[LIST] Result dir:\n"," - meta.json\n"," - nnscorer_search_index.faiss\n"," - patchcore_params.pkl\n"," - wrn50_l3.onnx\n"]}]},{"cell_type":"code","source":["# ===[ Robust: .faiss → gallery_f32.bin + threshold.json ]====================\n","import os, json, numpy as np\n","from pathlib import Path\n","\n","RESULT_DIR = Path(os.environ.get(\"RESULT_DIR\", \"/content/result/unknown\"))\n","THR_Q      = float(os.environ.get(\"THR_Q\", \"0.998\"))\n","METRIC     = \"cosine\"\n","\n","FAISS_PATH = RESULT_DIR / \"nnscorer_search_index.faiss\"\n","OUT_GAL    = RESULT_DIR / \"gallery_f32.bin\"\n","OUT_THR    = RESULT_DIR / \"threshold.json\"\n","OUT_META   = RESULT_DIR / \"gallery_meta.json\"\n","\n","print(\"[ENV] RESULT_DIR =\", RESULT_DIR)\n","print(\"[ENV] THR_Q      =\", THR_Q)\n","assert FAISS_PATH.exists(), f\"[ERROR] not found: {FAISS_PATH}\"\n","\n","# ---- faiss import (CPU fallback) ----\n","try:\n","    import faiss\n","except Exception:\n","    import sys, subprocess\n","    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"faiss-cpu\"], check=True)\n","    import faiss\n","\n","index = faiss.read_index(str(FAISS_PATH))\n","ntotal, d = index.ntotal, index.d\n","print(f\"[INFO] Loaded FAISS index: ntotal={ntotal}, d={d}, type={type(index).__name__}\")\n","\n","# ---- helper: unwrap to reach inner flat index if wrapped ----\n","def unwrap_flat(idx):\n","    seen = set()\n","    cur = idx\n","    while True:\n","        if id(cur) in seen:  # cycle guard\n","            break\n","        seen.add(id(cur))\n","        # Prefer direct Flat\n","        if hasattr(cur, \"xb\"):    # Flat index usually exposes xb\n","            return cur\n","        # Known wrappers\n","        if hasattr(cur, \"index\"):         # IndexIDMap, IndexPreTransform, IndexRefine, etc.\n","            cur = cur.index\n","            continue\n","        if hasattr(cur, \"base_index\"):    # some refine wrappers\n","            cur = cur.base_index\n","            continue\n","        # Nothing more to unwrap\n","        return cur\n","\n","flat = unwrap_flat(index)\n","using_xb = hasattr(flat, \"xb\")\n","\n","# ---- extract gallery vectors ----\n","if using_xb:\n","    # 1) Fast path: read xb pointer from inner Flat\n","    xb_np = faiss.rev_swig_ptr(flat.xb, ntotal * d)   # 1D view\n","    vecs  = np.array(xb_np, dtype=np.float32, copy=True).reshape(ntotal, d)\n","    print(f\"[INFO] extracted via xb pointer from {type(flat).__name__}, shape=({ntotal},{d})\")\n","else:\n","    # 2) Portable path: reconstruct(i)\n","    print(\"[INFO] xb not available; falling back to reconstruct(i) loop\")\n","    vecs = np.empty((ntotal, d), dtype=np.float32)\n","    for i in range(ntotal):\n","        ri = index.reconstruct(i)\n","        # ri may already be a numpy array or a Faiss FloatVector\n","        if isinstance(ri, np.ndarray):\n","            v = ri.astype(np.float32, copy=False)\n","        else:\n","            # Faiss vector -> numpy\n","            v = faiss.vector_float_to_array(ri).astype(np.float32, copy=False)\n","        if v.shape[0] != d:\n","            raise ValueError(f\"Reconstructed dim mismatch at {i}: got {v.shape}, expected ({d},)\")\n","        vecs[i] = v\n","    print(f\"[INFO] extracted via reconstruct loop, shape=({ntotal},{d})\")\n","\n","# ---- L2 normalize (for cosine metric) ----\n","norms = np.linalg.norm(vecs, axis=1, keepdims=True)\n","norms[norms < 1e-12] = 1.0\n","vecs_norm = (vecs / norms).astype(np.float32, copy=False)\n","\n","# ---- save gallery_f32.bin (row-major float32) ----\n","vecs_norm.tofile(str(OUT_GAL))\n","print(f\"[WRITE] {OUT_GAL}  (bytes={OUT_GAL.stat().st_size:,})\")\n","\n","# ---- compute threshold by LOO NN (cosine) ----\n","# use inner-product (cosine because normalized)\n","index_ip = faiss.IndexFlatIP(d)\n","index_ip.add(vecs_norm)\n","D, I = index_ip.search(vecs_norm, 2)   # [N,2]: self + nearest\n","sims_nn = D[:, 1]\n","dist_nn = (1.0 - sims_nn).astype(np.float32)\n","\n","thr_value = float(np.quantile(dist_nn, THR_Q))\n","print(f\"[INFO] LOO q={THR_Q} -> threshold = {thr_value:.6f}\")\n","\n","with open(OUT_THR, \"w\") as f:\n","    json.dump({\"metric\": METRIC, \"q\": THR_Q, \"value\": thr_value, \"ntotal\": int(ntotal)}, f, indent=2)\n","print(f\"[WRITE] {OUT_THR}\")\n","\n","with open(OUT_META, \"w\") as f:\n","    json.dump({\"dim\": int(d), \"ntotal\": int(ntotal), \"metric\": METRIC, \"flat_type\": type(flat).__name__}, f, indent=2)\n","print(f\"[WRITE] {OUT_META}\")\n","\n","print(\"\\n[LIST]\", RESULT_DIR)\n","for p in sorted(RESULT_DIR.glob(\"*\")):\n","    print(\" -\", p.name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Cae3XVpWEXJ","executionInfo":{"status":"ok","timestamp":1759148259617,"user_tz":-540,"elapsed":1018,"user":{"displayName":"백승일","userId":"02288854804009064039"}},"outputId":"cfc8bd0f-10e8-46ae-f5b8-5a025371de43"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[ENV] RESULT_DIR = /content/result/20250929\n","[ENV] THR_Q      = 0.998\n","[INFO] Loaded FAISS index: ntotal=4096, d=1024, type=IndexFlatL2\n","[INFO] xb not available; falling back to reconstruct(i) loop\n","[INFO] extracted via reconstruct loop, shape=(4096,1024)\n","[WRITE] /content/result/20250929/gallery_f32.bin  (bytes=16,777,216)\n","[INFO] LOO q=0.998 -> threshold = 0.050912\n","[WRITE] /content/result/20250929/threshold.json\n","[WRITE] /content/result/20250929/gallery_meta.json\n","\n","[LIST] /content/result/20250929\n"," - gallery_f32.bin\n"," - gallery_meta.json\n"," - meta.json\n"," - nnscorer_search_index.faiss\n"," - patchcore_params.pkl\n"," - threshold.json\n"," - wrn50_l3.onnx\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"JQ_MGpgUZHi8"},"execution_count":null,"outputs":[]}]}